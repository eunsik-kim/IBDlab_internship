{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.29.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.1.0.dev20230513+cu118)\n",
      "Collecting torchvision (from sentence_transformers)\n",
      "  Downloading torchvision-0.16.1-cp310-cp310-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.24.1)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting scipy (from sentence_transformers)\n",
      "  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nltk (from sentence_transformers)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.14.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.9.0)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.4.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.30.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.4.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.0rc1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: pytorch-triton==2.1.0+7d1a95b046 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.1.0+7d1a95b046)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.5.5)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.3)\n",
      "Collecting joblib (from nltk->sentence_transformers)\n",
      "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 kB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting threadpoolctl>=2.0.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Collecting torch>=1.6.0 (from sentence_transformers)\n",
      "  Downloading torch-2.1.1-cp310-cp310-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.5.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.6.0->sentence_transformers)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.6.0->sentence_transformers)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.6.0->sentence_transformers)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.6.0->sentence_transformers)\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.6.0->sentence_transformers)\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.6.0->sentence_transformers)\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.6.0->sentence_transformers)\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.6.0->sentence_transformers)\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.6.0->sentence_transformers)\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1 (from torch>=1.6.0->sentence_transformers)\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.6.0->sentence_transformers)\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.1.0 (from torch>=1.6.0->sentence_transformers)\n",
      "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.6.0->sentence_transformers)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.2.1)\n",
      "Building wheels for collected packages: sentence_transformers\n",
      "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=0506333416c156d285d6d3132bc5a1e96b268241ae201f402c0cce84f17ace54\n",
      "  Stored in directory: /.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
      "Successfully built sentence_transformers\n",
      "Installing collected packages: triton, threadpoolctl, scipy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, joblib, scikit-learn, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nltk, nvidia-cusolver-cu12, torch, torchvision, sentence_transformers\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.0.0\n",
      "    Uninstalling triton-2.0.0:\n",
      "      Successfully uninstalled triton-2.0.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0.dev20230513+cu118\n",
      "    Uninstalling torch-2.1.0.dev20230513+cu118:\n",
      "      Successfully uninstalled torch-2.1.0.dev20230513+cu118\n",
      "Successfully installed joblib-1.3.2 nltk-3.8.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 scikit-learn-1.3.2 scipy-1.11.4 sentence_transformers-2.2.2 threadpoolctl-3.2.0 torch-2.1.1 torchvision-0.16.1 triton-2.1.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.10 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!apt update\n",
    "!apt install sudo\n",
    "!sudo apt-get install python3.10-dev -y\n",
    "!pip install sentence_transformers pandas\n",
    "!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home2/eunsik12/Sbert'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.chdir('/home2/eunsik12/Sbert')\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>접수번호</th>\n",
       "      <th>업무</th>\n",
       "      <th>질문</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>220101032533665</td>\n",
       "      <td>상수도사업본부 중부수도사업소 요금과 요금1팀중구용산구 부서의 업무는 차량관리 69오...</td>\n",
       "      <td>수도 요금 누수 감액을 받았는데 장기간 누수가 의심되어 문의</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              접수번호                                                 업무   \n",
       "0  220101032533665  상수도사업본부 중부수도사업소 요금과 요금1팀중구용산구 부서의 업무는 차량관리 69오...  \\\n",
       "\n",
       "                                  질문  \n",
       "0  수도 요금 누수 감액을 받았는데 장기간 누수가 의심되어 문의  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('./질문_업무_db.csv',  encoding='utf-8', index_col=[0]) #cp949\n",
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('행정국 인력개발과 교육팀 부서의 업무는 직장교육 멘토링 포함 운영에 관한 사항 학습동아리 운영 및 연구 저술 공무원 지원에 관한 사항 독도아카데미에 관한 사항 대학생 아르바이트 운영 인턴십 경력증명 발급 등 5급 승진자 교육 관련 사항 9급 신임자 교육 관리 공무직 교육 관련 사항 자발적 학습조직 활성화 추진 지원 대직자 이하진',\n",
       " '서울시 대학생 아르바이트 선발 결과 문의')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.loc[1]['업무'], train_df.loc[1]['질문']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "class sbert_dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self, ):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            # if idx < 0 or idx >= len(self.df):\n",
    "            #     raise IndexError(f\"Index {idx} out of range for length {len(self.df)}\")\n",
    "            if type(idx) == int:\n",
    "                return [self.df.loc[idx, '질문'], self.df.loc[idx, '업무']]\n",
    "            return [[a,b] for a, b in zip(self.df.loc[idx, '질문'].tolist(), self.df.loc[idx, '업무'].tolist())]\n",
    "\n",
    "        except KeyError as e:\n",
    "            raise IndexError()\n",
    "train_df.dropna(inplace=True)\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "train_dataset = sbert_dataset(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, InputExample, losses,  evaluation, models\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def make_sts_input_example(dataset):\n",
    "    input_examples = []\n",
    "    for i, data in enumerate(dataset):\n",
    "        sentence1 = data[0]\n",
    "        sentence2 = data[1]\n",
    "        score = 1.\n",
    "        input_examples.append(InputExample(texts=[sentence1, sentence2], label=score))\n",
    "\n",
    "    return input_examples\n",
    "train_dataset = make_sts_input_example(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_embedding_model = models.Transformer('bert-base-uncased', max_seq_length=256)\n",
    "# pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "# model = SentenceTransformer(modules=[word_embedding_model, pooling_model], device ='cuda')\n",
    "\n",
    "\n",
    "#Define your train dataset, the dataloader and the train loss\n",
    "model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=16)\n",
    "train_loss = losses.CosineSimilarityLoss(model)\n",
    "\n",
    "sentences1 = ['상수도사업본부 중부수도사업소 요금과 요금1팀중구용산구 부서의 업무는 차량관리 69오6382 팀 휴대폰 관리 010 6428 요금심사 및 체납징수 신당2동 신당4동 청구동 신당3동 남영동', \n",
    "              '행정국 인력개발과 교육팀 부서의 업무는 직장교육 멘토링 포함 운영에 관한 사항 학습동아리 운영 및 연구 저술 공무원 지원에 관한 사항 독도아카데미에 관한 사항 대학생 아르바이트 운영 인턴십 경력증명 발급 등 5급 승진자 교육 관련 사항 9급 신임자 교육 관리 공무직 교육 관련 사항 자발적 학습조직 활성화 추진 지원 대직자 이하진']\n",
    "sentences2 = ['수도 요금 누수 감액을 받았는데 장기간 누수가 의심되어 문의', '서울시 대학생 아르바이트 선발 결과 문의']\n",
    "scores = [0.9, 0.99]\n",
    "\n",
    "evaluator = evaluation.EmbeddingSimilarityEvaluator(sentences1, sentences2, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████| 26007/26007 [1:00:17<00:00,  7.19it/s]\n",
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [1:00:17<00:00, 3617.22s/it]\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=100, evaluator=evaluator, evaluation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SentenceTransformer(\n",
      "  (0): Transformer({'max_seq_length': 128, 'do_lower_case': False}) with Transformer model: BertModel \n",
      "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 105.65it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 117.90it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1840]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "original_model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "\n",
    "vec1 = original_model.encode('미치겠네 이거', show_progress_bar=True, batch_size=32)\n",
    "vec2 = original_model.encode(sentences2[0], show_progress_bar=True, batch_size=32)\n",
    "\n",
    "util.cos_sim(vec1.reshape(1,-1), vec2.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 78.20it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 116.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "vec1 = model.encode('어떻게 이럴수가 있지?', show_progress_bar=True, batch_size=32)\n",
    "vec2 = model.encode(sentences2[0], show_progress_bar=True, batch_size=32)\n",
    "\n",
    "util.cos_sim(vec1.reshape(1,-1), vec2.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.0187882 ,  0.24176589, -0.09130772,  0.10925875,  0.16705008,\n",
       "         0.5254224 , -0.36401936,  0.13973144,  0.09008235, -0.14720711,\n",
       "         0.23667361, -0.1609391 ,  0.06406453,  0.06540694,  0.074884  ,\n",
       "        -0.44693372, -0.05529083, -0.5294041 , -0.41722044,  0.07923052],\n",
       "       dtype=float32),\n",
       " array([-0.01609456,  0.24628271, -0.09392784,  0.10840915,  0.17545818,\n",
       "         0.5303293 , -0.36541831,  0.13841566,  0.08577701, -0.14273088,\n",
       "         0.2314083 , -0.15272026,  0.06756931,  0.06899818,  0.06411265,\n",
       "        -0.45060453, -0.05140609, -0.522928  , -0.42235118,  0.08448441],\n",
       "       dtype=float32))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1[:20], vec2[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('ver1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9999032]], dtype=float32)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(vec1.reshape(1,-1), vec2.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>접수번호</th>\n",
       "      <th>업무</th>\n",
       "      <th>질문</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>220101032533665</td>\n",
       "      <td>상수도사업본부 중부수도사업소 요금과 요금1팀중구용산구 부서의 업무는 차량관리 69오...</td>\n",
       "      <td>수도 요금 누수 감액을 받았는데 장기간 누수가 의심되어 문의</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>220101038863665</td>\n",
       "      <td>행정국 인력개발과 교육팀 부서의 업무는 직장교육 멘토링 포함 운영에 관한 사항 학습...</td>\n",
       "      <td>서울시 대학생 아르바이트 선발 결과 문의</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>220102056263873</td>\n",
       "      <td>도시교통실 교통기획관 교통지도과 시스템운영관리팀 부서의 업무는 무인단속시스템 CCT...</td>\n",
       "      <td>구로구 불법주정차 신고건 조치 안됨 문의</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>220103021953646</td>\n",
       "      <td>도시교통실 교통기획관 택시정책과 택시면허팀 부서의 업무는 개인택시 인허가 및 운영 ...</td>\n",
       "      <td>서울시 개인택시 등록대수 확인 문의</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>220103023183091</td>\n",
       "      <td>재무국 세무과 부동산세팀 부서의 업무는 부동산 취득세 과징업무 총괄 및 운영 지원 ...</td>\n",
       "      <td>서울시 부동산 취득세 문의</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416104</th>\n",
       "      <td>416534</td>\n",
       "      <td>201231110833541</td>\n",
       "      <td>주차지도1팀 부서의 업무는 불법 주정차 순찰 및 단속업무</td>\n",
       "      <td>재택 송파구 주정차 단속 민원 석촌동 견인요청 추가 요청</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416105</th>\n",
       "      <td>416535</td>\n",
       "      <td>201231120783825</td>\n",
       "      <td>면목본동 행정팀 부서의 업무는 청원경찰</td>\n",
       "      <td>코로나 관련 가정집에서 인 이상 집합금지 신고한다고 하심</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416106</th>\n",
       "      <td>416536</td>\n",
       "      <td>201231122093825</td>\n",
       "      <td>주차지도1팀 부서의 업무는 불법 주정차 단속 종합계획 수립 팀예산 결산 주요 업무계...</td>\n",
       "      <td>불법주정차 단속되어 과태료 문의</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416107</th>\n",
       "      <td>416537</td>\n",
       "      <td>201231122573295</td>\n",
       "      <td>공중위생민원팀 부서의 업무는 식품 및 공중위생 영업신고</td>\n",
       "      <td>중구 음식점 코로나로인한 사회적 거리두기 방법문의</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416108</th>\n",
       "      <td>416538</td>\n",
       "      <td>201231126443135</td>\n",
       "      <td>청사방호실 부서의 업무는 청사 방호</td>\n",
       "      <td>안녕하세요서울 성동구에 있는 매봉산 공원도 내일 폐쇄하나요?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>416109 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index             접수번호   \n",
       "0            0  220101032533665  \\\n",
       "1            1  220101038863665   \n",
       "2            2  220102056263873   \n",
       "3            3  220103021953646   \n",
       "4            4  220103023183091   \n",
       "...        ...              ...   \n",
       "416104  416534  201231110833541   \n",
       "416105  416535  201231120783825   \n",
       "416106  416536  201231122093825   \n",
       "416107  416537  201231122573295   \n",
       "416108  416538  201231126443135   \n",
       "\n",
       "                                                       업무   \n",
       "0       상수도사업본부 중부수도사업소 요금과 요금1팀중구용산구 부서의 업무는 차량관리 69오...  \\\n",
       "1       행정국 인력개발과 교육팀 부서의 업무는 직장교육 멘토링 포함 운영에 관한 사항 학습...   \n",
       "2       도시교통실 교통기획관 교통지도과 시스템운영관리팀 부서의 업무는 무인단속시스템 CCT...   \n",
       "3       도시교통실 교통기획관 택시정책과 택시면허팀 부서의 업무는 개인택시 인허가 및 운영 ...   \n",
       "4       재무국 세무과 부동산세팀 부서의 업무는 부동산 취득세 과징업무 총괄 및 운영 지원 ...   \n",
       "...                                                   ...   \n",
       "416104                    주차지도1팀 부서의 업무는 불법 주정차 순찰 및 단속업무   \n",
       "416105                              면목본동 행정팀 부서의 업무는 청원경찰   \n",
       "416106  주차지도1팀 부서의 업무는 불법 주정차 단속 종합계획 수립 팀예산 결산 주요 업무계...   \n",
       "416107                     공중위생민원팀 부서의 업무는 식품 및 공중위생 영업신고   \n",
       "416108                                청사방호실 부서의 업무는 청사 방호   \n",
       "\n",
       "                                       질문  \n",
       "0       수도 요금 누수 감액을 받았는데 장기간 누수가 의심되어 문의  \n",
       "1                  서울시 대학생 아르바이트 선발 결과 문의  \n",
       "2                  구로구 불법주정차 신고건 조치 안됨 문의  \n",
       "3                     서울시 개인택시 등록대수 확인 문의  \n",
       "4                          서울시 부동산 취득세 문의  \n",
       "...                                   ...  \n",
       "416104    재택 송파구 주정차 단속 민원 석촌동 견인요청 추가 요청  \n",
       "416105    코로나 관련 가정집에서 인 이상 집합금지 신고한다고 하심  \n",
       "416106                  불법주정차 단속되어 과태료 문의  \n",
       "416107        중구 음식점 코로나로인한 사회적 거리두기 방법문의  \n",
       "416108  안녕하세요서울 성동구에 있는 매봉산 공원도 내일 폐쇄하나요?  \n",
       "\n",
       "[416109 rows x 4 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41610"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(len(train_df) * 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 332889/332889 [00:08<00:00, 41394.66it/s]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import losses\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "train_df['input'] = train_df.progress_apply(lambda x: InputExample(texts=[x.질문, x.업무]), axis = 1)\n",
    "test_df = train_df[-41610:].copy()\n",
    "train_df = train_df[:-41610] \n",
    "train_examples = list(train_df['input'])\n",
    "test_examples = list(test_df['input'])\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "test_dataloader = DataLoader(test_examples, shuffle=True, batch_size=16)\n",
    "\n",
    "train_loss = losses.MultipleNegativesRankingLoss(model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/scipy/stats/_stats_py.py:4781: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(msg))\n",
      "/usr/local/lib/python3.10/dist-packages/scipy/stats/_stats_py.py:5445: ConstantInputWarning: An input array is constant; the correlation coefficient is not defined.\n",
      "  warnings.warn(stats.ConstantInputWarning(warn_msg))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator = evaluation.EmbeddingSimilarityEvaluator(test_df['업무'].to_list(), test_df['질문'].to_list(), [1] * len(test_df))\n",
    "evaluator(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS', device= 'cuda')\n",
    "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=1, warmup_steps=1000, show_progress_bar = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 108.85it/s]\n",
      "Batches: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 121.04it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2490]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec1 = model.encode(sentences1[1], show_progress_bar=True, batch_size=32)\n",
    "vec2 = model.encode(sentences2[1], show_progress_bar=True, batch_size=32)\n",
    "\n",
    "util.cos_sim(vec1.reshape(1,-1), vec2.reshape(1,-1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
